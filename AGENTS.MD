# Agents Instructions for Sopra Steria Brand Audit Tool

## ðŸ¤– AI Agent Guidelines for Codebase Interaction

This document provides explicit instructions for AI agents (like GitHub Codex) on how to properly understand and work with this codebase.

---

## ðŸ“‹ **PROJECT IDENTIFICATION**

### **This is a PYTHON PROJECT, not Node.js**

**Primary Language:** Python 3.12+  
**Framework:** Streamlit (web dashboard)  
**Architecture:** Modular Python package with CLI and web interface  
**Dependencies:** Managed via `requirements.txt` and Python virtual environment

**âš ï¸ IMPORTANT:** If you see `package.json` files or JavaScript references, these are from Python dependencies (Playwright, Plotly) that include browser components. **DO NOT** treat this as a Node.js project.

---

## ðŸ—ï¸ **CODEBASE STRUCTURE**

```
sopra_steria/
â”œâ”€â”€ audit_tool/                    # Main Python package
â”‚   â”œâ”€â”€ __init__.py                # Package initialization
â”‚   â”œâ”€â”€ main.py                    # CLI entry point & orchestration
â”‚   â”œâ”€â”€ ai_interface.py            # AI provider abstraction (OpenAI/Anthropic)
â”‚   â”œâ”€â”€ scraper.py                 # Web scraping functionality
â”‚   â”œâ”€â”€ methodology_parser.py      # YAML configuration parser
â”‚   â”œâ”€â”€ persona_parser.py          # Markdown persona processor
â”‚   â”œâ”€â”€ multi_persona_packager.py  # Data aggregation
â”‚   â”œâ”€â”€ strategic_summary_generator.py # AI-powered summaries
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ methodology.yaml       # Audit scoring methodology
â”‚   â”‚   â””â”€â”€ unified_csv_columns.yaml # Data schema
â”‚   â”œâ”€â”€ dashboard/                 # Streamlit web interface
â”‚   â”‚   â”œâ”€â”€ brand_health_command_center.py # Main dashboard
â”‚   â”‚   â”œâ”€â”€ components/            # Reusable dashboard components
â”‚   â”‚   â””â”€â”€ pages/                 # Individual dashboard pages
â”‚   â”œâ”€â”€ templates/                 # AI prompt templates
â”‚   â””â”€â”€ tests/                     # Test suite
â”œâ”€â”€ audit_inputs/                  # Input data and configuration
â”‚   â”œâ”€â”€ personas/                  # Persona definitions (markdown)
â”‚   â”œâ”€â”€ prompts/                   # AI prompt templates
â”‚   â””â”€â”€ social_media/              # Social media audit data
â”œâ”€â”€ audit_outputs/                 # Generated audit reports
â”œâ”€â”€ audit_data/                    # Processed/unified datasets
â”œâ”€â”€ cache/                         # Web scraping cache
â”œâ”€â”€ product/                       # Documentation and specifications
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ launch_brand_health_command_center.sh # Dashboard launcher
â””â”€â”€ README.md                      # Project documentation
```

---

## ðŸŽ¯ **KEY CONCEPTS**

### **Brand Audit Methodology**

- **Scoring System:** 0-10 scale with descriptive categories
- **Tier Classification:** Pages classified as Tier 1 (Brand), Tier 2 (Value Prop), Tier 3 (Functional)
- **Multi-Persona Analysis:** 5 different business personas evaluate same content
- **Criteria-Based Evaluation:** Weighted scoring across brand and performance criteria

### **Data Flow**

1. **Input:** URLs + Persona definitions
2. **Scraping:** Web content extraction (cached)
3. **AI Analysis:** Content evaluation via OpenAI/Anthropic
4. **Scoring:** Methodology-based numerical scoring
5. **Aggregation:** Multi-persona data unification
6. **Visualization:** Streamlit dashboard presentation

---

## ðŸ”§ **DEVELOPMENT GUIDELINES**

### **Environment Setup**

```bash
# Always use Python virtual environment
python -m venv venv
source venv/bin/activate  # macOS/Linux
# venv\Scripts\activate   # Windows

# Install dependencies
pip install -r requirements.txt

# Launch dashboard
./launch_brand_health_command_center.sh
```

### **AI Provider Configuration**

- **Default Provider:** OpenAI (cost-effective)
- **Alternative:** Anthropic (premium quality)
- **Configuration:** Environment variables `OPENAI_API_KEY`, `ANTHROPIC_API_KEY`
- **Switching:** Modify `model_provider` parameter in `AIInterface()`

### **Code Patterns**

#### **Adding New Dashboard Pages**

```python
# File: audit_tool/dashboard/pages/N_ðŸŽ¯_Page_Name.py
import streamlit as st
from audit_tool.dashboard.components.data_loader import BrandHealthDataLoader

def main():
    st.title("ðŸŽ¯ Page Name")

    # Load data
    loader = BrandHealthDataLoader()
    datasets, master_df = loader.load_all_data()

    # Your page logic here

if __name__ == "__main__":
    main()
```

#### **AI Interface Usage**

```python
from audit_tool.ai_interface import AIInterface
from audit_tool.methodology_parser import MethodologyParser

# Initialize with OpenAI (default)
ai = AIInterface(model_provider="openai")

# Generate reports
methodology = MethodologyParser()
scorecard = ai.generate_hygiene_scorecard(
    url=url,
    page_content=content,
    persona_content=persona,
    methodology=methodology
)
```

#### **Data Loading Pattern**

```python
from audit_tool.dashboard.components.data_loader import BrandHealthDataLoader

loader = BrandHealthDataLoader()
datasets, master_df = loader.load_all_data()

# datasets contains: 'master', 'criteria_scores', 'experience', etc.
# master_df is the unified DataFrame with all audit data
```

---

## ðŸ“Š **DATA SCHEMA**

### **Unified Dataset Columns**

```python
# Key columns in master_df:
- page_id: str           # Unique page identifier
- url: str               # Full URL
- persona: str           # Persona name
- tier: str              # Page classification (tier_1, tier_2, tier_3)
- criterion_code: str    # Evaluation criterion identifier
- raw_score: float       # 0-10 numerical score
- final_score: float     # Weighted/adjusted score
- evidence: str          # Supporting quote/evidence
- descriptor: str        # Score interpretation
- weight_pct: float      # Criterion weight percentage
```

### **File Formats**

- **Input:** Markdown (personas), YAML (methodology), TXT (URLs)
- **Processing:** CSV (unified datasets), PKL (cache)
- **Output:** Markdown (reports), CSV (data exports)

---

## ðŸš¨ **COMMON PITFALLS & SOLUTIONS**

### **1. Node.js Confusion**

**Problem:** AI agents think this is a Node.js project  
**Solution:** This is Python. `package.json` files are from Playwright/Plotly dependencies.

### **2. AI Provider Defaults**

**Problem:** Hardcoded Anthropic defaults cause API errors  
**Solution:** Always default to OpenAI unless explicitly specified

### **3. Data Loading Issues**

**Problem:** Dashboard pages expect different data structures  
**Solution:** Use `BrandHealthDataLoader.load_all_data()` for consistency

### **4. Import Errors**

**Problem:** Module not found errors  
**Solution:** Ensure virtual environment is activated and dependencies installed

### **5. Streamlit Caching**

**Problem:** Data not updating in dashboard  
**Solution:** Use `@st.cache_data` decorators and clear cache when needed

---

## ðŸ§ª **TESTING GUIDELINES**

### **Running Tests**

```bash
# Full test suite
python audit_tool/tests/test_audit_tool.py

# Test individual components
python -c "from audit_tool.ai_interface import AIInterface; print('AI Interface OK')"
python -c "from audit_tool.main import run_audit; print('Main module OK')"
```

### **Expected Test Results**

- **YAML Configuration:** âœ… Should pass
- **Web Scraper:** âœ… Should pass
- **AI Interface:** âœ… Should pass
- **Persona Parsing:** âš ï¸ May have minor issues (acceptable)
- **Full Pipeline:** âš ï¸ Requires API keys

---

## ðŸ”„ **GIT WORKFLOW**

### **Git Remote Setup (CRITICAL for AI Agents)**

**If you're in a container/environment without git remote configured:**

```bash
# Add the GitHub remote
git remote add origin https://github.com/jasonlmagnus/sopra_steria.git

# Verify remote is configured
git remote -v
# Should output:
# origin  https://github.com/jasonlmagnus/sopra_steria.git (fetch)
# origin  https://github.com/jasonlmagnus/sopra_steria.git (push)
```

**ðŸš¨ IMPORTANT FOR AI AGENTS:**

- No more "no git remote" excuses for not creating PRs
- This is a PYTHON project - create PRs for ALL meaningful changes
- Use GitHub API or git commands - both should work now

### **Branch Strategy**

- **main:** Stable production code
- **dev:** Development integration branch
- **codex:** Active development branch (current)
- **Feature branches:** For specific features/fixes

### **Commit Guidelines**

```bash
# Feature commits
git commit -m "feat: Add new dashboard page for persona analysis"

# Bug fixes
git commit -m "fix: Resolve AI provider default to OpenAI"

# Documentation
git commit -m "docs: Update API interface documentation"

# Refactoring
git commit -m "refactor: Simplify data loading logic"
```

### **PR Creation (Multiple Methods)**

```bash
# Method 1: Traditional git workflow
git checkout -b feature/your-feature-name
git push origin feature/your-feature-name
# Create PR via GitHub interface: feature/your-feature-name â†’ codex

# Method 2: GitHub CLI (if available)
gh pr create --title "Your PR Title" --body "Description"

# Method 3: GitHub API (for containers)
# Use GitHub's REST API to create PRs programmatically
```

**ðŸ¤– AI AGENTS: You MUST create PRs for Python changes. No excuses.**

---

## ðŸŽ¨ **UI/UX PATTERNS**

### **Streamlit Dashboard Conventions**

- **Page Icons:** Use emoji prefixes (ðŸŽ¯, ðŸ“Š, ðŸš€, etc.)
- **Color Scheme:** Sopra Steria brand colors (navy #3d4a6b, red #dc3545)
- **Layout:** Sidebar navigation, main content area, expandable sections
- **Data Visualization:** Plotly charts with consistent styling

### **Component Structure**

```python
# Standard page layout
st.set_page_config(page_title="Page Name", page_icon="ðŸŽ¯", layout="wide")
st.title("ðŸŽ¯ Page Name")

with st.sidebar:
    # Filters and controls

col1, col2 = st.columns(2)
with col1:
    # Left content
with col2:
    # Right content
```

---

## ðŸ“š **DOCUMENTATION STANDARDS**

### **Code Documentation**

```python
def function_name(param1: str, param2: int) -> Dict[str, Any]:
    """
    Brief description of function purpose.

    Args:
        param1: Description of parameter
        param2: Description of parameter

    Returns:
        Description of return value

    Raises:
        ValueError: When invalid input provided
    """
```

### **README Updates**

- Keep installation instructions current
- Update feature lists when adding functionality
- Include screenshots for UI changes
- Maintain accurate dependency lists

---

## ðŸš€ **DEPLOYMENT NOTES**

### **Local Development**

```bash
# Quick start
./launch_brand_health_command_center.sh

# Manual start
streamlit run audit_tool/dashboard/brand_health_command_center.py
```

### **Production Considerations**

- Set environment variables for API keys
- Configure appropriate port/host settings
- Ensure data directories exist and are writable
- Monitor resource usage (AI API calls can be expensive)

---

## ðŸ“ž **SUPPORT & TROUBLESHOOTING**

### **Common Issues**

1. **Import errors:** Check virtual environment activation
2. **API failures:** Verify API keys and provider settings
3. **Data not loading:** Check file paths and permissions
4. **Dashboard crashes:** Review Streamlit logs for errors

### **Debug Mode**

```python
# Enable detailed logging
import logging
logging.basicConfig(level=logging.DEBUG)

# Streamlit debug mode
streamlit run app.py --logger.level debug
```

---

## ðŸŽ¯ **AGENT-SPECIFIC INSTRUCTIONS**

### **For Code Generation**

1. **Always** check if functionality already exists before creating new code
2. **Follow** existing patterns and conventions in the codebase
3. **Use** the established data loading and AI interface patterns
4. **Test** generated code against the existing test suite

### **For Bug Fixes**

1. **Identify** the root cause using the debugging guidelines above
2. **Check** if the issue is environment-related (API keys, dependencies)
3. **Follow** the established git workflow for fixes
4. **Update** tests if fixing test-related issues

### **For Feature Additions**

1. **Review** the product documentation in `/product/` directory
2. **Follow** the established architecture patterns
3. **Add** appropriate tests for new functionality
4. **Update** documentation as needed

---

**Remember:** This is a sophisticated brand audit tool with AI integration. Treat it as a professional Python application with proper software engineering practices.
